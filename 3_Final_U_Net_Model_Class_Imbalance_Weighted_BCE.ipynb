{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted BCE Loss With U-Net Model for Image Segmentation Using TensorFlow and GCP Data Integration\n",
        "\n",
        "## Overview\n",
        "This Colab notebook implements and trains a U-Net model for semantic image segmentation. The dataset consists of multi-band satellite images (`sentinel-tiles`) and their corresponding binary masks (`mask-tiles`). The workflow integrates with a Google Cloud Storage (GCP) bucket to stream data directly for training, validation, and testing.\n",
        "\n",
        "### Key Features:\n",
        "1. **Data Streaming from GCP**:\n",
        "   - Images and masks are organized in the GCP bucket into `train`, `dev`, and `test` subfolders under quarterly directories (`q1`, `q2`, etc.).\n",
        "   - Data is streamed dynamically to avoid loading large datasets entirely into memory.\n",
        "   - Images are resized to a target size (e.g., `128x128`) and normalized.\n",
        "\n",
        "2. **Model Architecture**:\n",
        "   - The U-Net model, a popular architecture for image segmentation tasks, is used.\n",
        "   - Key components:\n",
        "     - **Contracting Path (Encoder)**: Captures spatial features through convolutional and max-pooling layers.\n",
        "     - **Expanding Path (Decoder)**: Restores spatial resolution via transposed convolutions and concatenates with features from the encoder via skip connections.\n",
        "     - The model output is a binary mask prediction with the same spatial dimensions as the input image.\n",
        "\n",
        "3. **Training and Optimization**:\n",
        "   - Loss Function: ** Weighted Binary Crossentropy** is used for binary mask prediction tasks.\n",
        "   - Optimizer: **Adam Optimizer** for adaptive learning rate control.\n",
        "   - Evaluation Metric: **Accuracy** to monitor segmentation performance.\n",
        "   - Early Stopping: Halts training if validation loss does not improve for 5 consecutive epochs, restoring the best weights to prevent overfitting.\n",
        "\n",
        "4. **Data Pipeline**:\n",
        "   - Training, validation, and test datasets are created using TensorFlow's `tf.data.Dataset` from a custom generator function.\n",
        "   - The dataset is preprocessed to normalize pixel values, handle missing masks, and resize images and masks to a fixed shape.\n",
        "\n",
        "5. **Training Parameters**:\n",
        "   - **Batch Size**: 128 (modifiable based on system memory).\n",
        "   - **Target Image Size**: 128x128 pixels with 9 channels (for satellite imagery).\n",
        "   - **Epochs**: Up to 200 with early stopping.\n",
        "\n",
        "6. **Visualization**:\n",
        "   - Loss curves for both training and validation datasets are plotted to monitor convergence.\n",
        "   - The epoch where training stopped is displayed.\n",
        "\n",
        "7. **Evaluation**:\n",
        "   - The test dataset is used to evaluate the final model's performance, providing a test loss and accuracy score.\n",
        "\n",
        "### Workflow Outline:\n",
        "1. **Stream Data from GCP**:\n",
        "   - Dynamically load and preprocess satellite images and masks from GCP bucket paths.\n",
        "   - Handle missing or mismatched images/masks gracefully.\n",
        "\n",
        "2. **Model Training**:\n",
        "   - Train the U-Net model on the training dataset.\n",
        "   - Validate on the dev dataset and implement early stopping to optimize performance.\n",
        "\n",
        "3. **Evaluation**:\n",
        "   - Evaluate the trained model on the test dataset.\n",
        "   - Display test accuracy and loss metrics for performance benchmarking.\n",
        "\n"
      ],
      "metadata": {
        "id": "GUREt6xqLwWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runtime Requirements and Specify Parameters"
      ],
      "metadata": {
        "id": "QkFnIQ2VKg_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAV5tEVxavuQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install google-cloud-storage tensorflow tensorflow-addons rasterio\n",
        "from google.cloud import storage\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Drive and Authenticate with Google Cloud\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "bucket_name = \"230-project-tiles\"\n",
        "image_prefix = \"sentinel-tiles-harmonized/\"\n",
        "mask_prefix = \"mask-tiles-harmonized/\"\n",
        "batch_size = 64\n",
        "target_size = (128, 128, 9) # size of image to feed in\n",
        "bufffer_size = 100 # for shuffling\n",
        "epoch_num = 50 # number of epochs\n",
        "weights = [1.25, 5.0]  # [background, target]\n",
        "eval_metrics=[\n",
        "        'accuracy',                 # Accuracy\n",
        "        AUC(name=\"roc_auc\", curve='ROC'),  # ROC-AUC metric\n",
        "        Precision(name=\"precision\"),       # Precision\n",
        "        Recall(name=\"recall\")              # Recall\n",
        "    ]"
      ],
      "metadata": {
        "id": "2C2VJF9IR6TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OPTIONAL Sanity Check: Find Examples of Pineapple Plantations in Test Set\n",
        "\n",
        "# NOTE: This code is purely for visualization purposes if you are interested in knowing which tiles in the test set contain plantations\n",
        "def find_all_masks_with_ones(bucket_name, source_mask_prefix):\n",
        "    \"\"\"\n",
        "    Finds and prints the paths of all masks in the 'q1/test' folder of a GCP bucket\n",
        "    that contain at least one pixel with the value 1.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of the GCP bucket.\n",
        "        source_mask_prefix (str): Prefix for the mask files (e.g., 'mask-tiles/').\n",
        "    \"\"\"\n",
        "    # Initialize GCP storage client\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    # Get list of blobs in the 'q1/test' folder\n",
        "    mask_blobs = list(bucket.list_blobs(prefix=f\"{source_mask_prefix}test/q1/\"))\n",
        "    masks_with_ones = []\n",
        "\n",
        "    for blob in mask_blobs:\n",
        "        # Download the mask file locally\n",
        "        local_filename = f\"/tmp/{blob.name.split('/')[-1]}\"  # Use a temporary file\n",
        "        blob.download_to_filename(local_filename)\n",
        "\n",
        "        # Open the mask file using rasterio\n",
        "        with rasterio.open(local_filename) as src:\n",
        "            mask_data = src.read(1)  # Read the first band\n",
        "\n",
        "            # Check if there is any value of 1 in the mask\n",
        "            if (mask_data == 1).any():\n",
        "                masks_with_ones.append(blob.name)\n",
        "\n",
        "        # Remove the local file after processing (optional cleanup)\n",
        "        os.remove(local_filename)\n",
        "\n",
        "    # Print the paths of all masks with 1s\n",
        "    if masks_with_ones:\n",
        "        print(\"Masks with 1s found:\")\n",
        "        for mask_path in masks_with_ones:\n",
        "            print(mask_path)\n",
        "    else:\n",
        "        print(\"No masks with 1s found in the 'q1/test' folder.\")\n",
        "\n",
        "# Example usage\n",
        "bucket_name = \"230-project-tiles\"\n",
        "source_mask_prefix = \"mask-tiles/\"\n",
        "find_all_masks_with_ones(bucket_name, source_mask_prefix)\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "DD98yRjnCt4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize An Example Plantation and Mask\n",
        "\n",
        "\n",
        "# Inputs:\n",
        "bucket_name = \"230-project-tiles\" # GCP bucket name\n",
        "image_blob = \"sentinel-tiles-harmonized/test/q1/image_q1_2019_tile_3072_2048.tif\" # path to image tile to visualize\n",
        "mask_blob = \"mask-tiles-harmonized/test/q1/mask_q1_2019_tile_3072_2048.tif\" # path to mask tile to visualize\n",
        "# note that both image_blob and mask_blob can be retrived from the optional section below\n",
        "\n",
        "\n",
        "def download_from_gcp(bucket_name, blob_name, local_path):\n",
        "    \"\"\"\n",
        "    Download a file from a GCP bucket to a local path.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of the GCP bucket.\n",
        "        blob_name (str): Path to the file in the bucket.\n",
        "        local_path (str): Local path to save the downloaded file.\n",
        "    \"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(local_path)\n",
        "\n",
        "def visualize_image_and_mask_from_gcp(bucket_name, image_blob, mask_blob):\n",
        "    \"\"\"\n",
        "    Download and visualize an RGB image and its corresponding mask from a GCP bucket.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of the GCP bucket.\n",
        "        image_blob (str): Path to the image in the bucket.\n",
        "        mask_blob (str): Path to the mask in the bucket.\n",
        "    \"\"\"\n",
        "    # Temporary local paths\n",
        "    local_image_path = \"/tmp/image.tif\"\n",
        "    local_mask_path = \"/tmp/mask.tif\"\n",
        "\n",
        "    # Download the image and mask\n",
        "    download_from_gcp(bucket_name, image_blob, local_image_path)\n",
        "    download_from_gcp(bucket_name, mask_blob, local_mask_path)\n",
        "\n",
        "    # Load the RGB image\n",
        "    with rasterio.open(local_image_path) as src:\n",
        "        blue = src.read(1)\n",
        "        green = src.read(2)\n",
        "        red = src.read(3)\n",
        "        rgb_image = np.dstack((red, green, blue))  # Stack bands in RGB order\n",
        "\n",
        "        # Normalize for visualization\n",
        "        rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())\n",
        "\n",
        "    # Load the mask\n",
        "    with rasterio.open(local_mask_path) as src:\n",
        "        mask = src.read(1)\n",
        "\n",
        "    # Visualize the image and mask\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # RGB Image\n",
        "    axs[0].imshow(rgb_image)\n",
        "    axs[0].set_title(\"RGB Image\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    # Mask in Black and White\n",
        "    axs[1].imshow(mask, cmap=\"gray\")\n",
        "    axs[1].set_title(\"Mask (White is Plantation)\")\n",
        "    axs[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(local_image_path)\n",
        "    os.remove(local_mask_path)\n",
        "visualize_image_and_mask_from_gcp(bucket_name, image_blob, mask_blob)\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "qBrPkxKaET0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming Data from GCP Bucket"
      ],
      "metadata": {
        "id": "WGVPAunfKZxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note for Noramlization: the min and max values from the bands are retrieved from the following GEE code: https://code.earthengine.google.com/adb190fa3174ce71e80fb08af0635504\n",
        "\n",
        "def stream_data_from_gcp(bucket_name, image_prefix, mask_prefix, target_size=target_size):\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    for quarter in ['q1/', 'q2/', 'q3/', 'q4/']:\n",
        "        # List blobs\n",
        "        image_blobs = [blob for blob in bucket.list_blobs(prefix=f\"{image_prefix}{quarter}\") if blob.name.endswith('.tif')]\n",
        "        mask_blobs = [blob for blob in bucket.list_blobs(prefix=f\"{mask_prefix}{quarter}\") if blob.name.endswith('.tif')]\n",
        "\n",
        "        mask_blob_dict = {blob.name.split('/')[-1].replace(\"mask_\", \"image_\"): blob for blob in mask_blobs}\n",
        "\n",
        "        for image_blob in image_blobs:\n",
        "            image_name = image_blob.name.split('/')[-1]\n",
        "            if image_name not in mask_blob_dict:\n",
        "                print(f\"Missing mask for image: {image_blob.name}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Download image and mask\n",
        "                image_data = image_blob.download_as_bytes()\n",
        "                mask_data = mask_blob_dict[image_name].download_as_bytes()\n",
        "\n",
        "                # Read image\n",
        "                with rasterio.open(io.BytesIO(image_data)) as img:\n",
        "                    image = img.read()  # Read all bands, shape = (bands, height, width)\n",
        "                    image = np.moveaxis(image, 0, -1)  # Convert to (height, width, bands)\n",
        "\n",
        "                # Read mask\n",
        "                with rasterio.open(io.BytesIO(mask_data)) as msk:\n",
        "                    mask = msk.read(1)  # Read the first band (single-channel mask)\n",
        "\n",
        "                # Replace NaN values\n",
        "                image = np.nan_to_num(image, nan=0)\n",
        "                mask = np.nan_to_num(mask, nan=0)\n",
        "\n",
        "                # Ensure mask has a channel dimension\n",
        "                if len(mask.shape) == 2:  # If the mask is 2D\n",
        "                    mask = np.expand_dims(mask, axis=-1)  # Add channel dimension\n",
        "\n",
        "\n",
        "                # Resize images and masks\n",
        "                image = tf.image.resize_with_pad(image, target_size[0], target_size[1]).numpy()\n",
        "                mask = tf.image.resize_with_pad(mask, target_size[0], target_size[1]).numpy()\n",
        "\n",
        "\n",
        "                # Yield the processed image and mask\n",
        "                yield image, mask\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {image_blob.name}: {e}\")\n"
      ],
      "metadata": {
        "id": "FFW51wPNhCwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batches the Data\n",
        "def create_dataset(bucket_name, image_prefix, mask_prefix, batch_size=batch_size, buffer_size=buffer_size):\n",
        "    def generator():\n",
        "        return stream_data_from_gcp(bucket_name, image_prefix, mask_prefix)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(128, 128, 9), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(128, 128, 1), dtype=tf.float32)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Batch and repeat\n",
        "    dataset = (\n",
        "        dataset\n",
        "        .shuffle(buffer_size)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "yd_8sN0GhYRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "RTXDxfMGKWM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "def unet_model(input_shape=(128, 128, 9)):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling\n",
        "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    b = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(b)\n",
        "\n",
        "    # Upsampling\n",
        "    u1 = tf.keras.layers.UpSampling2D((2, 2))(b)\n",
        "    u1 = tf.keras.layers.Concatenate()([u1, c2])\n",
        "    c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    u2 = tf.keras.layers.UpSampling2D((2, 2))(c3)\n",
        "    u2 = tf.keras.layers.Concatenate()([u2, c1])\n",
        "    c4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "    c4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c4)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "oYqYeIzPd8-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Parameters + Early Stopping"
      ],
      "metadata": {
        "id": "TCiEXXhjKL93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import Precision, Recall, TruePositives, TrueNegatives, FalsePositives, FalseNegatives, BinaryAccuracy, AUC\n",
        "\n",
        "# Create dataset\n",
        "# Training dataset\n",
        "train_dataset = create_dataset(\n",
        "    bucket_name, f\"{image_prefix}train/\", f\"{mask_prefix}train/\", batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Dev dataset\n",
        "dev_dataset = create_dataset(\n",
        "    bucket_name, f\"{image_prefix}dev/\", f\"{mask_prefix}dev/\", batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Define the U-Net model\n",
        "model = unet_model()\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet_model(input_shape=target_size)\n",
        "model.summary()\n",
        "\n",
        "# custom weighted bce loss funtion\n",
        "def weighted_binary_crossentropy(weights):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
        "        loss = -weights[1] * y_true * tf.math.log(y_pred) - weights[0] * (1 - y_true) * tf.math.log(1 - y_pred)\n",
        "        return tf.reduce_mean(loss)\n",
        "    return loss\n",
        "\n",
        "# Create the weighted BCE loss function\n",
        "weighted_bce_loss = weighted_binary_crossentropy(weights)\n",
        "\n",
        "# Compile the model with the custom loss\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=weighted_bce_loss,\n",
        "    metrics=eval_metrics\n",
        ")\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",         # Monitor validation loss (dev set error)\n",
        "    patience=5,                 # Stop if no improvement for 5 epochs\n",
        "    restore_best_weights=True,  # Restore the weights of the best epoch\n",
        "    mode=\"min\"                  # Minimize validation loss\n",
        ")\n",
        "# Set up the ModelCheckpoint callback to save only the most recent model\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='model_latest.keras',  # Single file name, overwrites after each epoch\n",
        "    save_best_only=False,        # Save after every epoch, not just the best one\n",
        "    save_weights_only=False,     # Save the full model (architecture + weights)\n",
        "    verbose=1                    # Print a message when saving\n",
        ")\n",
        "\n",
        "class TrainValMetrics(Callback):\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        # Training metrics for the current batch\n",
        "        train_loss = logs.get(\"loss\")\n",
        "        train_accuracy = logs.get(\"accuracy\")\n",
        "        print(f\"Batch {batch + 1}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Training metrics (aggregated over the epoch)\n",
        "        train_loss = logs.get(\"loss\")\n",
        "        train_accuracy = logs.get(\"accuracy\")\n",
        "\n",
        "        # Validation metrics (aggregated over the epoch)\n",
        "        val_loss = logs.get(\"val_loss\")\n",
        "        val_accuracy = logs.get(\"val_accuracy\")\n",
        "        val_precision = logs.get(\"val_precision\")\n",
        "        val_recall = logs.get(\"val_recall\")\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}, \"\n",
        "              f\"Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.4f}, \"\n",
        "              f\"Validation Precision = {val_precision:.4f}, Validation Recall = {val_recall:.4f}\")\n",
        "\n",
        "train_val_metrics = TrainValMetrics()\n"
      ],
      "metadata": {
        "id": "uC198gVMhxe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Export\n"
      ],
      "metadata": {
        "id": "amoGWEnpKGBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,               # Training dataset\n",
        "    validation_data=dev_dataset, # Validation dataset (dev set)\n",
        "    epochs=epoch_num,                   # Maximum epochs\n",
        "    callbacks=[checkpoint_callback, train_val_metrics],  # Include checkpoint callback\n",
        ")\n",
        "\n",
        "# Print the epoch the training stopped at\n",
        "print(f\"Training stopped at epoch {len(history.epoch)}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# Save history as a JSON file\n",
        "with open('history.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "# Download the saved JSON file to your local machine\n",
        "files.download('history.json')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Dev Loss')\n",
        "plt.title('Training vs Dev Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wx3wbc44_Do5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}